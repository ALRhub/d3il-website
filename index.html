<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
<!--  <link rel="icon" href="./static/images/favicon.svg">-->
  <link rel="icon" href="./static/images/Untitled.ico">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->

<!--<div class="logo-container">-->
<!--    <img src="./static/Logo_KIT.svg" alt="Logo 1">-->
<!--    <img src="./static/alr-logo_large.png" alt="Logo 2">-->
<!--    <img src="./static/IRL_Logo_Light_blue.svg" alt="Logo 3">-->
<!--</div>-->


<!--<div class="row">-->
<!--        <div class="col-lg-3" style="padding-left: 50px; padding-top: 0;">-->
<!--          <img src="./static/Logo_KIT.svg" width="150px">-->
<!--        </div>-->
<!--        <div class="col-lg-2" style="padding-left: 0; padding-top: 0;">-->
<!--          <img src="./static/alr-logo_large.png" width="130px">-->
<!--        </div>-->
<!--        <div class="col-lg-2" style="padding-left: 0; padding-top: 0;">-->
<!--          <img src="./static/IRL_Logo_Light_blue.svg" width="150px">-->
<!--        </div>-->
<!--      </div>-->

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href=https://xiaogangjia.github.io/Personal_Website/ target=_blank>Xiaogang Jia</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a href=https://alr.iar.kit.edu/21_495.php target="_blank">Denis Blessing</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href=https://alr.iar.kit.edu/21_500.php target="_blank">Xinkai Jiang</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
              <a href=https://mbreuss.github.io/ target=_blank>Moritz Reuss</a><sup>2</sup>,
            </span>
            <span class="author-block">
              Atalay Donat<sup>1</sup>,
            </span>
            <span class="author-block">
              <a href=https://rudolf.intuitive-robots.net/ target=_blank>Rudolf Lioutikov</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href=https://alr.iar.kit.edu/21_65.php target=_blank>Gerhard Neumann</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Autonomous Learning Robots (ALR),</span>
            <span class="author-block"><sup>2</sup>Intuitive Robots Lab (IRL)</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Karlsruhe Institute of Technology</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://openreview.net/forum?id=6pPYRXKPpw"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2402.14606"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
<!--              <span class="link-block">-->
<!--                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fab fa-youtube"></i>-->
<!--                  </span>-->
<!--                  <span>Video</span>-->
<!--                </a>-->
<!--              </span>-->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/ALRhub/d3il"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1SQhbhzV85zf_ltnQ8Cbge2lsSWInxVa8/view?usp=drive_link"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
      <img src="./static/images/github_readme.gif">
    </div>
  </div>
</section>


<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Imitation learning with human data has demonstrated remarkable success in teaching robots in a wide range of skills.
            However, the inherent diversity in human behavior leads to the emergence of multi-modal data distributions, thereby presenting a formidable challenge
            for existing imitation learning algorithms.
            Quantifying a model’s capacity to capture and replicate this diversity effectively is still an open problem.
          </p>
          <p>
            In this work, we introduce simulation benchmark environments and the corresponding Datasets with Diverse human Demonstrations for Imitation Learning (D3IL),
            designed explicitly to evaluate a model’s ability to learn multi-modal behavior.
            Our environments are designed to involve multiple sub-tasks that need to be solved, consider manipulation of multiple objects which increases the diversity
            of the behavior and can only be solved by policies that rely on closed loop sensory feedback.
            Other available datasets are missing at least one of these challenging properties.
            To address the challenge of diversity quantification, we introduce tractable metrics that provide valuable insights into a model’s ability to acquire
            and reproduce diverse behaviors.
            These metrics offer a practical means to assess the robustness and versatility of imitation learning algorithms.
          </p>
          <p>
            Furthermore, we conduct a thorough evaluation of state-of-the-art methods on the proposed task suite.
            This evaluation serves as a benchmark for assessing their capability to learn diverse behaviors.
            Our findings shed light on the effectiveness of these methods in tackling the intricate problem of capturing and generalizing multi-modal human
            behaviors, offering a valuable reference for the design of future imitation learning algorithms.
            
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <h2 class="title is-3">Quantifying Diverse Behavior</h2>
    <div class="columns is-centered">
      <div class="column is-full-width">

      <img src="./static/images/traj_visualization.png" style="width: 100%; height: auto;">

      </div>
    </div>

    <h2 class="title is-3">Task Design Principles</h2>
    <div class="columns is-multiline">
      <div class="column is-half">
        
        <h3 class="title is-4">Diverse Behavior</h3>
        <div class="content has-text-justified">
          <p>
            Diversity is the central aspect of our task design. We intentionally design our tasks to encompass multiple viable approaches
            to successful task completion. To quantify the behavior diversity, we explicitly specify these distinct behaviors, each representing a legitimate solution.
          </p>
        </div>
        
        <h3 class="title is-4">Variable Trajectory Lengths</h3>
        <div class="content has-text-justified">
          <p>
            Our tasks incorporate variable trajectory lengths, replicating real-world scenarios where demonstrations may differ in duration.
            This design choice challenges our learning agents to handle non-uniform data sequences effectively.
            By accommodating varying trajectory lengths, our approach must learn to adapt and generalize to different time horizons, a critical property for real-world applications.
          </p>
        </div>

      </div>
      <div class="column is-half">
        
        <h3 class="title is-4">Multiple Human Demonstrators</h3>
        <div class="content has-text-justified">
          <p>
            To reflect the natural variability in human behavior and to obtain a richer dataset, we have collected
            demonstration data from multiple human demonstrators. This diversity in data sources introduces variations in the quality and style of demonstrations.
          </p>
        </div>

        <h3 class="title is-4">Task Variations & Closed-Loop Feedback</h3>
        <div class="content has-text-justified">
          <p>
            For most tasks, agents need to rely on sensory feedback
            to achieve a good performance which considerably increases the complexity of the learning task
            in comparison to learning open-loop trajectories. We achieve this by introducing task variations in
            every execution. For example, in every execution, the initial position of the objects will be different
            and the agent needs to adapt its behaviour accordingly.
          </p>
        </div>
    </div>
    </div>

    <!-- Tasks -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Tasks</h2>

        <!-- Avoiding -->
        <h3 class="title is-4">Avoiding</h3>
        <div class="content has-text-justified">
          <p>
            The Avoiding task requires the robot to reach the green
            finish line from a fixed initial position without colliding with one of
            the six obstacles. The task does not require object manipulation and
            is designed to test a model's ability to capture diversity. There are
            24 different ways of successfully completing the task.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/avoiding/obs_1.mp4"
                    type="video/mp4">
          </video>
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/avoiding/obs_2.mp4"
                    type="video/mp4">
          </video>
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/avoiding/obs_3.mp4"
                    type="video/mp4">
          </video>
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/avoiding/obs_4.mp4"
                    type="video/mp4">
          </video>
        </div>
        <br/>
        <!--/ Avoiding -->
        
        <!-- Aligning -->
        <h3 class="title is-4">Aligning</h3>
        <div class="content has-text-justified">
          <p>
            The Aligning task requires the robot to push a hollow
            box to a predefined target position and orientation. The task can be
            completed by either pushing the box from outside or inside.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/aligning/rp_inside.mp4"
                    type="video/mp4">
          </video>
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/aligning/rp_outside.mp4"
                    type="video/mp4">
          </video>
        </div>
        <br/>
        <!--/ Aligning -->
        
        <!-- Pushing -->
        <h3 class="title is-4">Pushing</h3>
        <div class="content has-text-justified">
          <p>
            This task requires the robot to push two blocks to fixed target zones.
            Having two blocks and two target zones results in 4 behaviors.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/pushing/bp-2023-09-29_05.12.24.mp4"
                    type="video/mp4">
          </video>
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/pushing/bp-2023-09-29_05.13.22.mp4"
                    type="video/mp4">
          </video>
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/pushing/bp-2023-09-29_05.14.19.mp4"
                    type="video/mp4">
          </video>
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/pushing/bp-2023-09-29_05.15.17.mp4"
                    type="video/mp4">
          </video>
        </div>
        <br/>
        <!--/ Pushing -->

        <!-- Sorting -->
        <h3 class="title is-4">Sorting</h3>
        <div class="content has-text-justified">
          <p>
            This task requires the robot to sort red and blue blocks to their color-matching target box.
            The number of behaviors is determined by the number of blocks.
            For 6 blocks, the task has many objects, is highly diverse (20 behaviours), requires complex manipulations, has high variation in trajectory length
            and is thus more challenging than the previous tasks.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/sorting/sorting-4-2023-09-29_05.28.10.mp4"
                    type="video/mp4">
          </video>
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/sorting/sorting_6.mp4"
                    type="video/mp4">
          </video>
        </div>
        <br/>
        <!--/ Sorting -->

        <!-- Stacking -->
        <h3 class="title is-4">Stacking</h3>
        <div class="content has-text-justified">
          <p>
            This task requires the robot to sort red and blue blocks to their color-matching target box.
            The number of behaviors is determined by the number of blocks.
            For 6 blocks, the task has many objects, is highly diverse (20 behaviours), requires complex manipulations, has high variation in trajectory length
            and is thus more challenging than the previous tasks.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/stacking/1111-2023-09-29_12.40.17.mp4"
                    type="video/mp4">
          </video>
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/stacking/1111-2023-09-29_12.44.50.mp4"
                    type="video/mp4">
          </video>
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/stacking/1111-2023-09-29_12.45.54.mp4"
                    type="video/mp4">
          </video>
        </div>
        <br/>
        <!--/ Stacking -->

        <!-- Arranging -->
        <h3 class="title is-4">Arranging</h3>
        <div class="content has-text-justified">
          <p>
            This task involves the robot arranging
            various objects on the table. Specifically, the robot is required to: i) flip
            the cup and place it in the yellow target zone, ii) position the banana
            on the plate, and iii) position the plate in the purple target zones. The
            diversity in this task is introduced by the order of these subtasks.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/arranging/arrange_1.mp4"
                    type="video/mp4">
          </video>
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/arranging/arrange_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <br/>
        <!--/ Arranging -->

        <!-- Inserting -->
        <h3 class="title is-4">Inserting</h3>
        <div class="content has-text-justified">
          <p>
            This task involves
            the robot pushing blocks to designated target zones. However, this task
            is more complex due to: i) the presence of three blocks and corresponding target zones, resulting in 6 diverse behaviours, ii) longer time horizons,
            and iii) the need for dexterous manipulations arising from additional
            constraints imposed by the gray barrier.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/inserting/insert-1.mp4"
                    type="video/mp4">
          </video>
          <video id="replay-video"
                 autoplay
                 controls
                 muted
                 preload
                 playsinline
                 width="49%">
            <source src="./static/videos/inserting/insert_2.mp4"
                    type="video/mp4">
          </video>
        </div>
        <br/>
        <!--/ Inserting -->

      </div>
    </div>
    <!--/ Tasks. -->

    <!-- Results -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2>
        <img src="./static/images/traj_visualization.png" style="width: 100%; height: auto;">
        <div class="content has-text-justified">
          <p>
            Visualization of 100 end-effector trajectories for different methods, as indicated by the sub-captions.
          </p>
        </div>
      </div>
    </div> -->


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{
jia2024towards,
title={Towards Diverse Behaviors: A Benchmark for Imitation Learning with Human Demonstrations},
author={Xiaogang Jia and Denis Blessing and Xinkai Jiang and Moritz Reuss and Atalay Donat and Rudolf Lioutikov and Gerhard Neumann},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=6pPYRXKPpw}
}</code></pre>
  </div>
</section>


<!--<footer class="footer">-->
<!--  <div class="container">-->
<!--    <div class="content has-text-centered">-->
<!--      <a class="icon-link"-->
<!--         href="./static/videos/nerfies_paper.pdf">-->
<!--        <i class="fas fa-file-pdf"></i>-->
<!--      </a>-->
<!--      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>-->
<!--        <i class="fab fa-github"></i>-->
<!--      </a>-->
<!--    </div>-->
<!--    <div class="columns is-centered">-->
<!--      <div class="column is-8">-->
<!--        <div class="content">-->
<!--          <p>-->
<!--            This website is licensed under a <a rel="license"-->
<!--                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative-->
<!--            Commons Attribution-ShareAlike 4.0 International License</a>.-->
<!--          </p>-->
<!--          <p>-->
<!--            This means you are free to borrow the <a-->
<!--              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,-->
<!--            we just ask that you link back to this page in the footer.-->
<!--            Please remember to remove the analytics code included in the header of the website which-->
<!--            you do not want on your website.-->
<!--          </p>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--  </div>-->
<!--</footer>-->

</body>
</html>
